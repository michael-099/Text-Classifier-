{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (2.2.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: click in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy nltk scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"News Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      headline category               date  \\\n",
      "0  የኦሊምፒክ ማጣሪያ ተሳታፊዎች የሚለዩበት ቻምፒዮና እየተካሄደ ይገኛል     ስፖርት   January 14, 2021   \n",
      "1                                   አዲስ ዘመን ድሮ     መዝናኛ  December 28, 2020   \n",
      "2             የአረንጓዴ ጎርፍ በጎ አድራጎት አምባሳደሮች ተሰየሙ     ስፖርት    January 6, 2021   \n",
      "3        የሊጉ በቢዝነስ ሞዴል መመራት አበረታች ጅምር መሆኑ ተገለጸ     ስፖርት    January 6, 2021   \n",
      "4    የኦሊምፒክ ሥራ አስፈፃሚው እስከ ቶኪዮ ኦሊምፒክ ማግስት ይቀጥላል     ስፖርት    January 6, 2021   \n",
      "\n",
      "  views                                            article  \\\n",
      "0     2  ብርሃን ፈይሳየኢትዮጵያ ቦክስ ፌዴሬሽን በየዓመቱ የሚያዘጋጀው የክለቦች ቻ...   \n",
      "1     4   የአዲስ ዘመን ጋዜጣ ቀደምት ዘገባዎች በእጅጉ ተነባቢ ዛሬም ላገኛቸው በ...   \n",
      "2     6  ቦጋለ አበበየአዲስ አበባ ከተማ አስተዳደር ስፖርት ኮሚሽን ከኢትዮጵያ አረ...   \n",
      "3     5  ብርሃን ፈይሳአዲስ አበባ፡- የኢትዮጵያ ፕሪምየር ሊግ በሼር ካምፓኒ እንዲ...   \n",
      "4    12  ቦጋለ አበበ የኢትዮጵያ ኦሊምፒክ ኮሚቴ አርባ አምስተኛ መደበኛ ጠቅላላ ጉ...   \n",
      "\n",
      "                                link  \n",
      "0  https://www.press.et/Ama/?p=39481  \n",
      "1  https://www.press.et/Ama/?p=38334  \n",
      "2  https://www.press.et/Ama/?p=39010  \n",
      "3  https://www.press.et/Ama/?p=39011  \n",
      "4  https://www.press.et/Ama/?p=39012  \n",
      "                                              headline    category  \\\n",
      "51478  የ2011 በጀት ዓመት የውጭ ዲሎማሲያዊ ተግባራት ስኬታማ እንደነበሩ ተገለጸ        ፖለቲካ   \n",
      "51479   አቶ አገኘሁ ተሻገር የሰላም ግንባታና የሕዝብ ደህንነት ኃላፊ ሆነው ተሾሙ        ፖለቲካ   \n",
      "51480               የአማራ ክልል ምክር ቤት የ230 ዳኞችን ሹመት አጸደቀ        ፖለቲካ   \n",
      "51481  ሃምሌ 22 ለሚካሄደው የችግኝ ተከላ መርሀ-ግብር 54 ሚሊየን ብር ተመድቧል  ሀገር አቀፍ ዜና   \n",
      "51482         ለህግ የበላይነት መከበር ሁሉም በጋራ መስራት እንዳለበት ተጠቆመ  ሀገር አቀፍ ዜና   \n",
      "\n",
      "                date    views  \\\n",
      "51478  July 26, 2019  Unknown   \n",
      "51479  July 25, 2019  Unknown   \n",
      "51480  July 25, 2019  Unknown   \n",
      "51481  July 25, 2019  Unknown   \n",
      "51482  July 25, 2019  Unknown   \n",
      "\n",
      "                                                 article  \\\n",
      "51478  በ2011 በጀት ዓመት የተከናወኑ የውጭ ዲፕሎማሲያዊ ተግባራት ስኬታማ እን...   \n",
      "51479  አቶ አገኘሁ ተሻገር የአማራ ክልል የሰላም ግንባታና የህዝብ ደህንነት ቢሮ...   \n",
      "51480  የአማራ ክልል ምክር ቤት የ230 ዳኞችን ሹመት አጸደቀየአማራ ክልል ምክር...   \n",
      "51481  በዘንድሮ በጀት ዓመት ከ4 ቢሊዮን ችግኝ በላይ ለመትከል እቅድ መያዙ ይታ...   \n",
      "51482  የፍትህ እኩልነትን ለማረጋገጥ የህግ የበላይነትን የማክበርና የማስከብር ሃ...   \n",
      "\n",
      "                                  link  \n",
      "51478  https://waltainfo.com/am/31264/  \n",
      "51479  https://waltainfo.com/am/31259/  \n",
      "51480  https://waltainfo.com/am/31260/  \n",
      "51481  https://waltainfo.com/am/32585/  \n",
      "51482  https://waltainfo.com/am/32586/  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())  # First 5 rows\n",
    "print(data.tail())  # Last 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51483 entries, 0 to 51482\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   headline  51470 non-null  object\n",
      " 1   category  51482 non-null  object\n",
      " 2   date      51483 non-null  object\n",
      " 3   views     51483 non-null  object\n",
      " 4   article   51483 non-null  object\n",
      " 5   link      51483 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 2.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())  # Data types, non-null values, memory usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51483, 6)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)  # (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headline    13\n",
      "category     1\n",
      "date         0\n",
      "views        0\n",
      "article      0\n",
      "link         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())  # Count missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51470, 6)\n"
     ]
    }
   ],
   "source": [
    "data=data.dropna() # removing rows with null values because they are not many\n",
    "print(data.shape)  # (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ስፖርት', 'መዝናኛ', 'ሀገር አቀፍ ዜና', 'ቢዝነስ', 'ዓለም አቀፍ ዜና', 'ፖለቲካ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_char(token):\n",
    "    subs = [\n",
    "        ('[ሃኅኃሐሓኻ]', 'ሀ'), ('[ሑኁዅ]', 'ሁ'), ('[ኂሒኺ]', 'ሂ'),\n",
    "        ('[ኌሔዄ]', 'ሄ'), ('[ሕኅ]', 'ህ'), ('[ኆሖኾ]', 'ሆ'),\n",
    "        ('[ሠ]', 'ሰ'), ('[ሡ]', 'ሱ'), ('[ሢ]', 'ሲ'),\n",
    "        ('[ሣ]', 'ሳ'), ('[ሤ]', 'ሴ'), ('[ሥ]', 'ስ'),\n",
    "        ('[ሦ]', 'ሶ'), ('[ዓኣዐ]', 'አ'), ('[ዑ]', 'ኡ'),\n",
    "        ('[ዒ]', 'ኢ'), ('[ዔ]', 'ኤ'), ('[ዕ]', 'እ'),\n",
    "        ('[ዖ]', 'ኦ'), ('[ጸ]', 'ፀ'), ('[ጹ]', 'ፁ'),\n",
    "        ('[ጺ]', 'ፂ'), ('[ጻ]', 'ፃ'), ('[ጼ]', 'ፄ'),\n",
    "        ('[ጽ]', 'ፅ'), ('[ጾ]', 'ፆ'), ('(ሉ[ዋአ])', 'ሏ'),\n",
    "        ('(ሙ[ዋአ])', 'ሟ'), ('(ቱ[ዋአ])', 'ቷ'), ('(ሩ[ዋአ])', 'ሯ'),\n",
    "        ('(ሱ[ዋአ])', 'ሷ'), ('(ሹ[ዋአ])', 'ሿ'), ('(ቁ[ዋአ])', 'ቋ'),\n",
    "        ('(ቡ[ዋአ])', 'ቧ'), ('(ቹ[ዋአ])', 'ቿ'), ('(ሁ[ዋአ])', 'ኋ'),\n",
    "        ('(ኑ[ዋአ])', 'ኗ'), ('(ኙ[ዋአ])', 'ኟ'), ('(ኩ[ዋአ])', 'ኳ'),\n",
    "        ('(ዙ[ዋአ])', 'ዟ'), ('(ጉ[ዋአ])', 'ጓ'), ('(ደ[ዋአ])', 'ዷ'),\n",
    "        ('(ጡ[ዋአ])', 'ጧ'), ('(ጩ[ዋአ])', 'ጯ'), ('(ጹ[ዋአ])', 'ጿ'),\n",
    "        ('(ፉ[ዋአ])', 'ፏ'), ('[ቊ]', 'ቁ'), ('[ኵ]', 'ኩ')\n",
    "    ]\n",
    "    \n",
    "    for pattern, replacement in subs:\n",
    "        token = re.sub(pattern, replacement, token)\n",
    "\n",
    "    return token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['article'] = data['article'].str.replace('[^\\w\\s]','')\n",
    "data['article'] = data['article'].apply(lambda x: normalize_char(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization Split the Amharic text into individual words (tokens) using a tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\micha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [ብርሀን, ፈይሳየኢትዮጵያ, ቦክስ, ፌዴሬሽን, በየአመቱ, የሚያዘጋጀው, ...\n",
      "1    [የአዲስ, ዘመን, ጋዜጣ, ቀደምት, ዘገባዎች, በእጅጉ, ተነባቢ, ዛሬም,...\n",
      "2    [ቦጋለ, አበበየአዲስ, አበባ, ከተማ, አስተዳደር, ስፖርት, ኮሚሽን, ከ...\n",
      "3    [ብርሀን, ፈይሳአዲስ, አበባ፡-, የኢትዮጵያ, ፕሪምየር, ሊግ, በሼር, ...\n",
      "4    [ቦጋለ, አበበ, የኢትዮጵያ, ኦሊምፒክ, ኮሚቴ, አርባ, አምስተኛ, መደበ...\n",
      "Name: tokens, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt_tab')\n",
    "data['tokens'] = data['article'].apply(lambda x: word_tokenize(x))\n",
    "print(data['tokens'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword Removal Remove common words (stopwords) that don’t add meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "amharic_stopwords = ['እንዲሁም', 'እና', 'የሆነ', 'ወይም', 'ለምሳሌ']  # Add more stopwords\n",
    "data['tokens'] = data['tokens'].apply(lambda x: [word for word in x if word not in amharic_stopwords])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization (Converting Text to Numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust the feature size\n",
    "X = vectorizer.fit_transform(data['article'])  # Convert text to vectors\n",
    "y = data['category']  # Labels for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8324266563046435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\envs\\news_classifier\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  ሀገር አቀፍ ዜና       0.79      0.88      0.84      4095\n",
      "        መዝናኛ       0.87      0.61      0.72       134\n",
      "        ስፖርት       0.98      0.97      0.97      2096\n",
      "        ቢዝነስ       0.68      0.56      0.62       767\n",
      "  ዓለም አቀፍ ዜና       0.88      0.83      0.85      1345\n",
      "        ፖለቲካ       0.77      0.70      0.74      1857\n",
      "\n",
      "    accuracy                           0.83     10294\n",
      "   macro avg       0.83      0.76      0.79     10294\n",
      "weighted avg       0.83      0.83      0.83     10294\n",
      "\n",
      "[[3615    4   26  105   88  257]\n",
      " [  43   82    2    2    5    0]\n",
      " [  67    1 2025    0    1    2]\n",
      " [ 241    3    0  430    6   87]\n",
      " [ 174    2    8   10 1114   37]\n",
      " [ 414    2    2   82   54 1303]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news_classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
